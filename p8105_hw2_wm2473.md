p8105_hw2_wm2473
================
2022-10-01

``` r
library(tidyverse)
```

    ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──
    ## ✔ ggplot2 3.3.6      ✔ purrr   0.3.4 
    ## ✔ tibble  3.1.8      ✔ dplyr   1.0.10
    ## ✔ tidyr   1.2.0      ✔ stringr 1.4.1 
    ## ✔ readr   2.1.2      ✔ forcats 0.5.2 
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()

``` r
library(readxl)
```

## Problem 1

``` r
transpotation = 
  read_csv(
    "data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
    col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>% 
  janitor::clean_names() %>% 
  select(
    line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entry, exit_only, vending, entrance_type, 
    ada) %>% 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))

#Short paragraph about the dataset: These data are not tidy. Route number should be a variable, as should route. That is, to obtain a tidy dataset we would need to convert "route" variables from wide to long format. We cleaned and selected the data that we needed like "line", "station_name", "station_latitude", station_longtitude and so on. And we change the variable in entry from yes and no to TRUE OR FALSE.
```

``` r
transpotation %>% 
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 465 × 2
    ##    station_name             line    
    ##    <chr>                    <chr>   
    ##  1 25th St                  4 Avenue
    ##  2 36th St                  4 Avenue
    ##  3 45th St                  4 Avenue
    ##  4 53rd St                  4 Avenue
    ##  5 59th St                  4 Avenue
    ##  6 77th St                  4 Avenue
    ##  7 86th St                  4 Avenue
    ##  8 95th St                  4 Avenue
    ##  9 9th St                   4 Avenue
    ## 10 Atlantic Av-Barclays Ctr 4 Avenue
    ## # … with 455 more rows

``` r
## From this chunk, we can know that the number of rows are the same as the number of unique stations is 465.
```

``` r
transpotation %>% 
  filter(ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 84 × 2
    ##    station_name                   line           
    ##    <chr>                          <chr>          
    ##  1 Atlantic Av-Barclays Ctr       4 Avenue       
    ##  2 DeKalb Av                      4 Avenue       
    ##  3 Pacific St                     4 Avenue       
    ##  4 Grand Central                  42nd St Shuttle
    ##  5 34th St                        6 Avenue       
    ##  6 47-50th Sts Rockefeller Center 6 Avenue       
    ##  7 Church Av                      6 Avenue       
    ##  8 21st St                        63rd Street    
    ##  9 Lexington Av                   63rd Street    
    ## 10 Roosevelt Island               63rd Street    
    ## # … with 74 more rows

``` r
## There are 84 stations are ADA compliant.
```

``` r
transpotation %>% 
  filter(vending == "NO") %>% 
  pull(entry) %>% 
  mean
```

    ## [1] 0.3770492

``` r
## The porprotion will be 0.377.
```

``` r
  transpotation %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A") %>% 
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 60 × 2
    ##    station_name                  line           
    ##    <chr>                         <chr>          
    ##  1 Times Square                  42nd St Shuttle
    ##  2 125th St                      8 Avenue       
    ##  3 145th St                      8 Avenue       
    ##  4 14th St                       8 Avenue       
    ##  5 168th St - Washington Heights 8 Avenue       
    ##  6 175th St                      8 Avenue       
    ##  7 181st St                      8 Avenue       
    ##  8 190th St                      8 Avenue       
    ##  9 34th St                       8 Avenue       
    ## 10 42nd St                       8 Avenue       
    ## # … with 50 more rows

``` r
transpotation %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A", ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 17 × 2
    ##    station_name                  line            
    ##    <chr>                         <chr>           
    ##  1 14th St                       8 Avenue        
    ##  2 168th St - Washington Heights 8 Avenue        
    ##  3 175th St                      8 Avenue        
    ##  4 34th St                       8 Avenue        
    ##  5 42nd St                       8 Avenue        
    ##  6 59th St                       8 Avenue        
    ##  7 Inwood - 207th St             8 Avenue        
    ##  8 West 4th St                   8 Avenue        
    ##  9 World Trade Center            8 Avenue        
    ## 10 Times Square-42nd St          Broadway        
    ## 11 59th St-Columbus Circle       Broadway-7th Ave
    ## 12 Times Square                  Broadway-7th Ave
    ## 13 8th Av                        Canarsie        
    ## 14 Franklin Av                   Franklin        
    ## 15 Euclid Av                     Fulton          
    ## 16 Franklin Av                   Fulton          
    ## 17 Howard Beach                  Rockaway

``` r
## The distinct stations serve A train are 60 and 17 are ADA compliant.
```

# Problem 2

# Mr. Trash Wheel sheet clean up.

``` r
trash_wheel = 
  read_excel(
    "data/Trash Wheel Collection Data.xlsx" )%>%
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(sports_balls =as.integer(sports_balls),
         sports_balls= round(sports_balls),
         table_name = "trash_wheel",
         year = as.numeric(year),
         dumpster = as.character(dumpster)) %>% 
  select(-x15,-x16)
```

    ## New names:
    ## • `` -> `...15`
    ## • `` -> `...16`

``` r
##Descript dataset: Cleaning the Trash Wheel Collection dataset, dropping the NA of dumpster, changing the sports_balls character to integer and also input one column called "trash_wheel" used to join the sheet later. There is 547 observations and 15 variables in the sheet.
```

``` r
trash_wheel2 =  filter(trash_wheel, year==2020) 
sum(trash_wheel2$sports_balls)
```

    ## [1] 856

``` r
#The total number of sports ball collected by Mr. Trash Wheel is 856.
```

# Professor Trash Wheel clean up.

``` r
Professor_trash_wheel =   
  read_excel(
    "data/Trash Wheel Collection Data.xlsx", sheet = 2) %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(homes_powered = round(homes_powered,digits = 2),
         dumpster = as.character(dumpster),
         year = as.numeric(year),
         table_name = "Professor_trash_wheel") 
sum(Professor_trash_wheel$weight_tons)
```

    ## [1] 190.12

``` r
##Descript dataset: Cleaning the Professor trash wheel Collection dataset, dropping the NA of dumpster, round the home_powered to two digits number and also input one column called "Professor_trash_wheel" used to join the sheet later. The sum of the weight_tons is 190.12. There is 94 observations and 14 variables in the sheet.  
```

``` r
join_table = full_join(trash_wheel,Professor_trash_wheel, copy = FALSE)
```

    ## Joining, by = c("dumpster", "month", "year", "date", "weight_tons",
    ## "volume_cubic_yards", "plastic_bottles", "polystyrene", "cigarette_butts",
    ## "glass_bottles", "grocery_bags", "chip_bags", "homes_powered", "table_name")

``` r
## There are 15 variables and 641 observations. Key variables example I provided are dumpster, month, year, date, weight_tons, volumn_cubic_yards.The total weight of trash collected by Professor Trash Wheel is 190.12. The total number of sports ball collected by Mr. Trash Wheel is 856.
```

## Problem 3

# Clean the pols_month dataset.

``` r
pols_month = read_csv("data/fivethirtyeight_datasets/fivethirtyeight_datasets/pols-month.csv") %>% 
  separate(mon, into = c("year", "month", "day"), sep = "-") %>%
  mutate(month =  month.abb [as.numeric(month)]) %>% 
  pivot_longer(starts_with("prez"),
               names_prefix = "prez_",
               names_to = "president", 
               values_to = "num") %>% 
  mutate(num =as.numeric(num)) %>% 
  filter(num != 0 ) %>% 
  select(-day,-num)
```

    ## Rows: 822 Columns: 9
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
# This dataset we create a new column president, separate the "mon" into year, month and day. And I filter the num column, keeping the 1 and 2 in the list. So my dataset is just include the president and the type of president dem or gov.
```

``` r
# library for the capital changing
library(stringr)
```

``` r
snp = read_csv("data/fivethirtyeight_datasets/fivethirtyeight_datasets/snp.csv") %>% 
  janitor::clean_names() %>%
  mutate(date=lubridate::mdy(date)) %>% 
  separate(date, into = c("year", "month", "day"), convert= TRUE) %>% 
   mutate(month =  month.abb [as.numeric(month)], year = ifelse(as.numeric(year)<=2022, as.numeric(year), as.numeric(year)-100), year = as.character(year)) %>% 
  arrange(year, month)
```

    ## Rows: 787 Columns: 2
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (1): date
    ## dbl (1): close
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
snp
```

    ## # A tibble: 787 × 4
    ##    year  month   day close
    ##    <chr> <chr> <int> <dbl>
    ##  1 1950  Apr       3  18.0
    ##  2 1950  Aug       1  18.4
    ##  3 1950  Dec       1  20.4
    ##  4 1950  Feb       1  17.2
    ##  5 1950  Jan       3  17.0
    ##  6 1950  Jul       3  17.8
    ##  7 1950  Jun       1  17.7
    ##  8 1950  Mar       1  17.3
    ##  9 1950  May       1  18.8
    ## 10 1950  Nov       1  19.5
    ## # … with 777 more rows

``` r
unemployment = read_csv("data/fivethirtyeight_datasets/fivethirtyeight_datasets/unemployment.csv") %>% 
  janitor::clean_names() %>% 
  na.omit() %>% 
  pivot_longer(jan:dec,
               names_to = "month",
               values_to = "output") %>%
  mutate(month = str_to_title(month))
```

    ## Rows: 68 Columns: 13
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
unemployment
```

    ## # A tibble: 804 × 3
    ##     year month output
    ##    <dbl> <chr>  <dbl>
    ##  1  1948 Jan      3.4
    ##  2  1948 Feb      3.8
    ##  3  1948 Mar      4  
    ##  4  1948 Apr      3.9
    ##  5  1948 May      3.5
    ##  6  1948 Jun      3.6
    ##  7  1948 Jul      3.6
    ##  8  1948 Aug      3.9
    ##  9  1948 Sep      3.8
    ## 10  1948 Oct      3.7
    ## # … with 794 more rows

# join datasets “snp”&“pols”, and merge unemployment into the results

``` r
join_datasets = right_join(pols_month,snp, copy = FALSE)
```

    ## Joining, by = c("year", "month")

``` r
final_join = merge(join_datasets, unemployment)


##Write a short paragraph about these datasets. Explain briefly what each dataset contained, and describe the resulting dataset (e.g. give the dimension, range of years, and names of key variables).

#For the first dataset pol_month, it contain lots of column. The key variable will be year, month, president and the type of party they belong to. The range of year is 1947 to 2015. It has 9 variables and 822 observations. The second dataset snp, it contains the key variables year, month, day and close. The range of year 1950 to 2015. It contain 4 variables and 787 observations.  The key variable of third dataset unemployment, it contains year, mon and output. The range of year is 1948 to 2014. It has 3 variables and 804 observations. After the combining and merging, the final join_datasets contains year, month, president, num, day, close and value. It contain 12 variables and 780 observations. The range of year from 1950 to 2014. 
```
